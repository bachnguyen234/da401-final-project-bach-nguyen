{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b096fcbb",
   "metadata": {},
   "source": [
    "### 1. Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5770fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_regression\n",
    "sns.set()\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59257de3",
   "metadata": {},
   "source": [
    "### 2. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "deb2e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "outdir = \"../output_reports\"\n",
    "outdir_graph = \"../figures\"\n",
    "data = os.path.join(datadir, \"NSDUH_2023_subset_raw.csv\")\n",
    "\n",
    "variables_used = [\n",
    "    # Survey design variables \n",
    "    \"ANALWT2_C\", \"VESTR_C\", \"VEREP\",\n",
    "    # Primary outcomes\n",
    "    \"SUTRTPY\", \"MHTRTPY\",\n",
    "    # Secondary (telehealth) outcomes\n",
    "    \"TELEAPTYR\", \"IRSUTPHVID\", \"IRMHTPHVID\",\n",
    "    # Demographic predictors\n",
    "    \"CATAG6\", \"IRSEX\", \"NEWRACE2\",\n",
    "    # Socioeconomic predictors\n",
    "    \"IRMARIT\", \"IREDUHIGHST2\", \"IRWRKSTAT18\",\n",
    "    \"IRINSUR4\", \"INCOME\",\n",
    "    # Clinical severity predictors\n",
    "    \"IRPYUD5ALC\", \"IRPYUD5MRJ\", \"KSSLR6YR\",\n",
    "    # Behavioral predictors\n",
    "    \"IRALCFY\", \"IRMJFY\", \"ILLYR\",\n",
    "    # Risk perception predictors\n",
    "    \"RSKCIGPKD\", \"RSKMRJWK\"\n",
    "]\n",
    "\n",
    "df_og = pd.read_csv(data, usecols = variables_used, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a925a",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning & Remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d8968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"TELEAPTYR\"] = df[\"TELEAPTYR\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:95: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"IRMARIT\"] = df[\"IRMARIT\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:131: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"IRWRKSTAT18\"] = df[\"IRWRKSTAT18\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:145: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"IRINSUR4\"] = df[\"IRINSUR4\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:200: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"ILLYR\"] = df[\"ILLYR\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:218: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"RSKCIGPKD\"] = df[\"RSKCIGPKD\"].replace({\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_50848\\3851752860.py:242: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"RSKMRJWK\"] = df[\"RSKMRJWK\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# Simple yes/no in 0/1 form\n",
    "binary_map_01 = {\"0\": \"No\", \"1\": \"Yes\"}\n",
    "\n",
    "# Age (CATAG6)\n",
    "age_map = {\n",
    "    \"1\": \"12-17\",\n",
    "    \"2\": \"18-25\",\n",
    "    \"3\": \"26-34\",\n",
    "    \"4\": \"35-49\",\n",
    "    \"5\": \"50-64\",\n",
    "    \"6\": \"65+\"\n",
    "}\n",
    "\n",
    "# Sex at birth (IRSEX)\n",
    "sex_map = {\"1\":\"Male\",\"2\":\"Female\"}\n",
    "\n",
    "race_map = {\n",
    "    \"1\": \"Non-Hispanic White\",\n",
    "    \"2\": \"Non-Hispanic Black/African American\",\n",
    "    \"3\": \"Non-Hispanic Native American/Alaska Native\",\n",
    "    \"4\": \"Non-Hispanic Native Hawaiian/Other Pacific Islander\",\n",
    "    \"5\": \"Non-Hispanic Asian\",\n",
    "    \"6\": \"Non-Hispanic more than one race\",\n",
    "    \"7\": \"Hispanic\"\n",
    "}\n",
    "\n",
    "# Family income (INCOME)\n",
    "income_map = {\n",
    "    \"1\":\"< $20,000\",\n",
    "    \"2\":\"$20,000-$49,999\",\n",
    "    \"3\":\"$50,000-$74,999\",\n",
    "    \"4\":\"$75,000+\"\n",
    "}\n",
    "\n",
    "df = df_og.copy()\n",
    "\n",
    "# Convert survey design variables to numeric\n",
    "df[\"ANALWT2_C\"] = pd.to_numeric(df[\"ANALWT2_C\"], errors=\"coerce\")\n",
    "df[\"VESTR_C\"]   = pd.to_numeric(df[\"VESTR_C\"], errors=\"coerce\")\n",
    "df[\"VEREP\"]     = pd.to_numeric(df[\"VEREP\"], errors=\"coerce\")\n",
    "\n",
    "df[\"SUTRTPY_lbl\"] = df[\"SUTRTPY\"].map(binary_map_01)\n",
    "# Convert to numeric for modeling\n",
    "df[\"SUTRTPY\"] = pd.to_numeric(df[\"SUTRTPY\"], errors=\"coerce\")\n",
    "\n",
    "df[\"MHTRTPY_lbl\"] = df[\"MHTRTPY\"].map(binary_map_01)\n",
    "# Convert to numeric for modeling\n",
    "df[\"MHTRTPY\"] = pd.to_numeric(df[\"MHTRTPY\"], errors=\"coerce\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"TELEAPTYR_lbl\"] = df[\"TELEAPTYR\"].map({\n",
    "    \"1\": \"Yes\",\n",
    "    \"2\": \"No\",\n",
    "    \"85\": \"Bad data\",\n",
    "    \"94\": \"Don't know\",\n",
    "    \"97\": \"Refused\",\n",
    "    \"98\": \"Blank\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (1 = Yes, 0 = No, NaN for all nonresponse codes)\n",
    "df[\"TELEAPTYR\"] = df[\"TELEAPTYR\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 0,\n",
    "    \"85\": np.nan,\n",
    "    \"94\": np.nan,\n",
    "    \"97\": np.nan,\n",
    "    \"98\": np.nan\n",
    "}).astype(\"float\")\n",
    "\n",
    "df[\"IRSUTPHVID_lbl\"] = df[\"IRSUTPHVID\"].map(binary_map_01)\n",
    "df[\"IRSUTPHVID\"] = pd.to_numeric(df[\"IRSUTPHVID\"], errors=\"coerce\")\n",
    "\n",
    "df[\"IRMHTPHVID_lbl\"] = df[\"IRMHTPHVID\"].map(binary_map_01)\n",
    "df[\"IRMHTPHVID\"] = pd.to_numeric(df[\"IRMHTPHVID\"], errors=\"coerce\")\n",
    "\n",
    "df[\"CATAG6_lbl\"] = df[\"CATAG6\"].map(age_map)\n",
    "df[\"CATAG6\"] = pd.to_numeric(df[\"CATAG6\"], errors=\"coerce\")\n",
    "\n",
    "df[\"IRSEX_lbl\"] = df[\"IRSEX\"].map(sex_map)\n",
    "df[\"IRSEX\"] = pd.to_numeric(df[\"IRSEX\"], errors=\"coerce\")\n",
    "\n",
    "df[\"NEWRACE2_lbl\"] = df[\"NEWRACE2\"].map(race_map)\n",
    "df[\"NEWRACE2\"] = pd.to_numeric(df[\"NEWRACE2\"], errors=\"coerce\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"IRMARIT_lbl\"] = df[\"IRMARIT\"].map({\n",
    "    \"1\": \"Married\",\n",
    "    \"2\": \"Widowed\",\n",
    "    \"3\": \"Divorced or Separated\",\n",
    "    \"4\": \"Never Been Married\",\n",
    "    \"99\": \"Legitimate skip (<=14 years old)\"\n",
    "})\n",
    "\n",
    "# Convert to numeric, set skip to NaN\n",
    "df[\"IRMARIT\"] = df[\"IRMARIT\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 4,\n",
    "    \"99\": np.nan\n",
    "}).astype(\"float\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"IREDUHIGHST2_lbl\"] = df[\"IREDUHIGHST2\"].map({\n",
    "    \"1\": \"Fifth grade or less\",\n",
    "    \"2\": \"Sixth grade\",\n",
    "    \"3\": \"Seventh grade\",\n",
    "    \"4\": \"Eighth grade\",\n",
    "    \"5\": \"Ninth grade\",\n",
    "    \"6\": \"Tenth grade\",\n",
    "    \"7\": \"Eleventh or Twelfth grade, no diploma\",\n",
    "    \"8\": \"High school diploma/GED\",\n",
    "    \"9\": \"Some college credit, no degree\",\n",
    "    \"10\": \"Associate's degree (AA, AS)\",\n",
    "    \"11\": \"College graduate or higher\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (ordinal: 1–11)\n",
    "df[\"IREDUHIGHST2\"] = pd.to_numeric(df[\"IREDUHIGHST2\"], errors=\"coerce\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"IRWRKSTAT18_lbl\"] = df[\"IRWRKSTAT18\"].map({\n",
    "    \"1\": \"Employed full time\",\n",
    "    \"2\": \"Employed part time\",\n",
    "    \"3\": \"Unemployed\",\n",
    "    \"4\": \"Other (not in labor force)\",\n",
    "    \"99\": \"Legitimate skip (age 12–14)\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (1–4), recode 99 to NaN\n",
    "df[\"IRWRKSTAT18\"] = df[\"IRWRKSTAT18\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 4,\n",
    "    \"99\": np.nan\n",
    "}).astype(\"float\")\n",
    "\n",
    "df[\"IRINSUR4_lbl\"] = df[\"IRINSUR4\"].map({\n",
    "    \"1\": \"Yes, covered by health insurance\",\n",
    "    \"2\": \"No, not covered by health insurance\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (1 = Yes, 0 = No)\n",
    "df[\"IRINSUR4\"] = df[\"IRINSUR4\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 0\n",
    "}).astype(\"float\")\n",
    "\n",
    "df[\"INCOME_lbl\"] = df[\"INCOME\"].map(income_map)\n",
    "df[\"INCOME\"] = pd.to_numeric(df[\"INCOME\"], errors=\"coerce\")\n",
    "\n",
    "# Convert to numeric (1–3), set '.' (college dorm) to NaN\n",
    "\n",
    "df[\"IRPYUD5ALC_lbl\"] = df[\"IRPYUD5ALC\"].map(binary_map_01)\n",
    "df[\"IRPYUD5ALC\"] = pd.to_numeric(df[\"IRPYUD5ALC\"], errors=\"coerce\")\n",
    "\n",
    "df[\"IRPYUD5MRJ_lbl\"] = df[\"IRPYUD5MRJ\"].map(binary_map_01)\n",
    "df[\"IRPYUD5MRJ\"] = pd.to_numeric(df[\"IRPYUD5MRJ\"], errors=\"coerce\")\n",
    "\n",
    "df[\"KSSLR6YR\"] = pd.to_numeric(df[\"KSSLR6YR\"], errors=\"coerce\")\n",
    "# Ensure values outside 0–24 are treated as missing (paranoid safety)\n",
    "df.loc[~df[\"KSSLR6YR\"].between(0, 24, inclusive=\"both\"), \"KSSLR6YR\"] = np.nan\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"IRALCFY_lbl\"] = df[\"IRALCFY\"].map({\n",
    "    \"991\": \"Never used alcohol\",\n",
    "    \"993\": \"No past-year use\"\n",
    "})\n",
    "\n",
    "# Convert to numeric, treating 991 and 993 as 0 (no use), others keep their day counts\n",
    "df[\"IRALCFY\"] = df[\"IRALCFY\"].replace({\n",
    "    \"991\": 0,\n",
    "    \"993\": 0\n",
    "})\n",
    "df[\"IRALCFY\"] = pd.to_numeric(df[\"IRALCFY\"], errors=\"coerce\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"IRMJFY_lbl\"] = df[\"IRMJFY\"].map({\n",
    "    \"991\": \"Never used marijuana\",\n",
    "    \"993\": \"No past-year use\"\n",
    "})\n",
    "\n",
    "# Convert to numeric, treating 991 and 993 as 0 (no use), others keep their day counts\n",
    "df[\"IRMJFY\"] = df[\"IRMJFY\"].replace({\n",
    "    \"991\": 0,\n",
    "    \"993\": 0\n",
    "})\n",
    "df[\"IRMJFY\"] = pd.to_numeric(df[\"IRMJFY\"], errors=\"coerce\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"ILLYR_lbl\"] = df[\"ILLYR\"].map({\n",
    "    \"0\": \"Did not use in past year\",\n",
    "    \"1\": \"Used in past year\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (binary: 0/1)\n",
    "df[\"ILLYR\"] = df[\"ILLYR\"].replace({\n",
    "    \"0\": 0,\n",
    "    \"1\": 1\n",
    "}).astype(\"float\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"RSKCIGPKD_lbl\"] = df[\"RSKCIGPKD\"].map({\n",
    "    \"1\": \"No risk\",\n",
    "    \"2\": \"Slight risk\",\n",
    "    \"3\": \"Moderate risk\",\n",
    "    \"4\": \"Great risk\",\n",
    "    \"85\": \"Bad data\",\n",
    "    \"94\": \"Don't know\",\n",
    "    \"97\": \"Refused\",\n",
    "    \"98\": \"Blank\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (ordinal 1–4), set nonresponse codes to NaN\n",
    "df[\"RSKCIGPKD\"] = df[\"RSKCIGPKD\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 4,\n",
    "    \"85\": np.nan,\n",
    "    \"94\": np.nan,\n",
    "    \"97\": np.nan,\n",
    "    \"98\": np.nan\n",
    "}).astype(\"float\")\n",
    "\n",
    "# Create a labeled version\n",
    "df[\"RSKMRJWK_lbl\"] = df[\"RSKMRJWK\"].map({\n",
    "    \"1\": \"No risk\",\n",
    "    \"2\": \"Slight risk\",\n",
    "    \"3\": \"Moderate risk\",\n",
    "    \"4\": \"Great risk\",\n",
    "    \"85\": \"Bad data\",\n",
    "    \"94\": \"Don't know\",\n",
    "    \"97\": \"Refused\",\n",
    "    \"98\": \"Blank\"\n",
    "})\n",
    "\n",
    "# Convert to numeric (ordinal 1–4), set nonresponse codes to NaN\n",
    "df[\"RSKMRJWK\"] = df[\"RSKMRJWK\"].replace({\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4\": 4,\n",
    "    \"85\": np.nan,\n",
    "    \"94\": np.nan,\n",
    "    \"97\": np.nan,\n",
    "    \"98\": np.nan\n",
    "}).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba99c826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MissingCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>MissingPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KSSLR6YR</th>\n",
       "      <td>41230</td>\n",
       "      <td>56705</td>\n",
       "      <td>72.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRALCFY_lbl</th>\n",
       "      <td>33076</td>\n",
       "      <td>56705</td>\n",
       "      <td>58.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRMJFY_lbl</th>\n",
       "      <td>14279</td>\n",
       "      <td>56705</td>\n",
       "      <td>25.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRWRKSTAT18</th>\n",
       "      <td>11572</td>\n",
       "      <td>56705</td>\n",
       "      <td>20.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRMARIT</th>\n",
       "      <td>5581</td>\n",
       "      <td>56705</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TELEAPTYR</th>\n",
       "      <td>1083</td>\n",
       "      <td>56705</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSKMRJWK</th>\n",
       "      <td>945</td>\n",
       "      <td>56705</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSKCIGPKD</th>\n",
       "      <td>765</td>\n",
       "      <td>56705</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRSEX</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEREP</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANALWT2_C</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VESTR_C</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRALCFY</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRINSUR4</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWRACE2</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IREDUHIGHST2</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATAG6</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRPYUD5MRJ</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRPYUD5ALC</th>\n",
       "      <td>0</td>\n",
       "      <td>56705</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MissingCount  Total  MissingPercent\n",
       "KSSLR6YR             41230  56705           72.71\n",
       "IRALCFY_lbl          33076  56705           58.33\n",
       "IRMJFY_lbl           14279  56705           25.18\n",
       "IRWRKSTAT18          11572  56705           20.41\n",
       "IRMARIT               5581  56705            9.84\n",
       "TELEAPTYR             1083  56705            1.91\n",
       "RSKMRJWK               945  56705            1.67\n",
       "RSKCIGPKD              765  56705            1.35\n",
       "IRSEX                    0  56705            0.00\n",
       "VEREP                    0  56705            0.00\n",
       "ANALWT2_C                0  56705            0.00\n",
       "VESTR_C                  0  56705            0.00\n",
       "IRALCFY                  0  56705            0.00\n",
       "INCOME                   0  56705            0.00\n",
       "IRINSUR4                 0  56705            0.00\n",
       "NEWRACE2                 0  56705            0.00\n",
       "IREDUHIGHST2             0  56705            0.00\n",
       "CATAG6                   0  56705            0.00\n",
       "IRPYUD5MRJ               0  56705            0.00\n",
       "IRPYUD5ALC               0  56705            0.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work = df.copy()  \n",
    "\n",
    "# Compute missing counts and percentages\n",
    "missing_summary = (\n",
    "    work.isna().sum()\n",
    "    .to_frame(\"MissingCount\")\n",
    "    .assign(\n",
    "        Total=work.shape[0],\n",
    "        MissingPercent=lambda x: (x[\"MissingCount\"] / x[\"Total\"] * 100).round(2)\n",
    "    )\n",
    "    .sort_values(\"MissingPercent\", ascending=False)\n",
    ")\n",
    "\n",
    "# Display top missing variables\n",
    "missing_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ab0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = [\"MHTRTPY_lbl\", \"SUTRTPY_lbl\",\n",
    "    \"CATAG6_lbl\",\"IRSEX_lbl\",\"NEWRACE2_lbl\",\n",
    "    \"IRMARIT_lbl\",\"IREDUHIGHST2_lbl\",\"IRWRKSTAT18_lbl\",\n",
    "    \"IRINSUR4_lbl\",\"INCOME_lbl\",\n",
    "    \"IRPYUD5ALC_lbl\",\"IRPYUD5MRJ_lbl\",\"ILLYR_lbl\",\n",
    "    \"RSKCIGPKD_lbl\",\"RSKMRJWK_lbl\",\n",
    "    \"IRMJFY_lbl\", \"IRALCFY_lbl\"\n",
    "]\n",
    "\n",
    "# Create a dictionary to store results\n",
    "value_counts_dict = {}\n",
    "\n",
    "for col in cols_to_check:\n",
    "    counts = (\n",
    "        df[col]\n",
    "        .value_counts(dropna=False)\n",
    "        .rename_axis(col)\n",
    "        .reset_index(name=\"Count\")\n",
    "    )\n",
    "    counts[\"Percent\"] = (counts[\"Count\"] / len(df) * 100).round(2)\n",
    "    value_counts_dict[col] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5015cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MHTRTPY_lbl':   MHTRTPY_lbl  Count  Percent\n",
       " 0          No  41075    72.44\n",
       " 1         Yes  15630    27.56,\n",
       " 'SUTRTPY_lbl':   SUTRTPY_lbl  Count  Percent\n",
       " 0          No  53838    94.94\n",
       " 1         Yes   2867     5.06,\n",
       " 'CATAG6_lbl':   CATAG6_lbl  Count  Percent\n",
       " 0      18-25  13587    23.96\n",
       " 1      35-49  12355    21.79\n",
       " 2      12-17  11572    20.41\n",
       " 3      26-34   9171    16.17\n",
       " 4        65+   5060     8.92\n",
       " 5      50-64   4960     8.75,\n",
       " 'IRSEX_lbl':   IRSEX_lbl  Count  Percent\n",
       " 0    Female  30560    53.89\n",
       " 1      Male  26145    46.11,\n",
       " 'NEWRACE2_lbl':                                         NEWRACE2_lbl  Count  Percent\n",
       " 0                                 Non-Hispanic White  31067    54.79\n",
       " 1                                           Hispanic  11932    21.04\n",
       " 2                Non-Hispanic Black/African American   6723    11.86\n",
       " 3                                 Non-Hispanic Asian   2758     4.86\n",
       " 4                    Non-Hispanic more than one race   2732     4.82\n",
       " 5         Non-Hispanic Native American/Alaska Native   1199     2.11\n",
       " 6  Non-Hispanic Native Hawaiian/Other Pacific Isl...    294     0.52,\n",
       " 'IRMARIT_lbl':                         IRMARIT_lbl  Count  Percent\n",
       " 0                Never Been Married  26755    47.18\n",
       " 1                           Married  18316    32.30\n",
       " 2  Legitimate skip (<=14 years old)   5581     9.84\n",
       " 3             Divorced or Separated   4670     8.24\n",
       " 4                           Widowed   1383     2.44,\n",
       " 'IREDUHIGHST2_lbl':                          IREDUHIGHST2_lbl  Count  Percent\n",
       " 0              College graduate or higher  15021    26.49\n",
       " 1                 High school diploma/GED  12180    21.48\n",
       " 2          Some college credit, no degree   9087    16.03\n",
       " 3             Associate's degree (AA, AS)   3956     6.98\n",
       " 4   Eleventh or Twelfth grade, no diploma   3815     6.73\n",
       " 5                             Ninth grade   2715     4.79\n",
       " 6                             Tenth grade   2661     4.69\n",
       " 7                            Eighth grade   2393     4.22\n",
       " 8                           Seventh grade   2001     3.53\n",
       " 9                             Sixth grade   1903     3.36\n",
       " 10                    Fifth grade or less    973     1.72,\n",
       " 'IRWRKSTAT18_lbl':                IRWRKSTAT18_lbl  Count  Percent\n",
       " 0           Employed full time  22182    39.12\n",
       " 1   Other (not in labor force)  13444    23.71\n",
       " 2  Legitimate skip (age 12–14)  11572    20.41\n",
       " 3           Employed part time   6712    11.84\n",
       " 4                   Unemployed   2795     4.93,\n",
       " 'IRINSUR4_lbl':                           IRINSUR4_lbl  Count  Percent\n",
       " 0     Yes, covered by health insurance  51432     90.7\n",
       " 1  No, not covered by health insurance   5273      9.3,\n",
       " 'INCOME_lbl':         INCOME_lbl  Count  Percent\n",
       " 0         $75,000+  23867    42.09\n",
       " 1  $20,000-$49,999  15398    27.15\n",
       " 2        < $20,000   9202    16.23\n",
       " 3  $50,000-$74,999   8238    14.53,\n",
       " 'IRPYUD5ALC_lbl':   IRPYUD5ALC_lbl  Count  Percent\n",
       " 0             No  50513    89.08\n",
       " 1            Yes   6192    10.92,\n",
       " 'IRPYUD5MRJ_lbl':   IRPYUD5MRJ_lbl  Count  Percent\n",
       " 0             No  51614    91.02\n",
       " 1            Yes   5091     8.98,\n",
       " 'ILLYR_lbl':                   ILLYR_lbl  Count  Percent\n",
       " 0  Did not use in past year  40663    71.71\n",
       " 1         Used in past year  16042    28.29,\n",
       " 'RSKCIGPKD_lbl':    RSKCIGPKD_lbl  Count  Percent\n",
       " 0     Great risk  36351    64.11\n",
       " 1  Moderate risk  12616    22.25\n",
       " 2    Slight risk   3964     6.99\n",
       " 3        No risk   3009     5.31\n",
       " 4     Don't know    492     0.87\n",
       " 5          Blank    187     0.33\n",
       " 6        Refused     84     0.15\n",
       " 7       Bad data      2     0.00,\n",
       " 'RSKMRJWK_lbl':     RSKMRJWK_lbl  Count  Percent\n",
       " 0    Slight risk  17167    30.27\n",
       " 1  Moderate risk  13234    23.34\n",
       " 2        No risk  12735    22.46\n",
       " 3     Great risk  12624    22.26\n",
       " 4     Don't know    666     1.17\n",
       " 5          Blank    195     0.34\n",
       " 6        Refused     82     0.14\n",
       " 7       Bad data      2     0.00,\n",
       " 'IRMJFY_lbl':              IRMJFY_lbl  Count  Percent\n",
       " 0  Never used marijuana  31198    55.02\n",
       " 1                   NaN  14279    25.18\n",
       " 2      No past-year use  11228    19.80,\n",
       " 'IRALCFY_lbl':           IRALCFY_lbl  Count  Percent\n",
       " 0                 NaN  33076    58.33\n",
       " 1  Never used alcohol  16479    29.06\n",
       " 2    No past-year use   7150    12.61}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e71e6",
   "metadata": {},
   "source": [
    "### 4. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63bac5",
   "metadata": {},
   "source": [
    "#### 4.1. LASSO Logistic Regression Model for SUTRTPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95ef01af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (weighted): 0.760\n",
      "Accuracy (weighted, thr=0.5): 0.957\n",
      "Selected features (non-zero): 44\n",
      "+1.1558  IRPYUD5ALC_1.0\n",
      "+1.0937  ILLYR_1.0\n",
      "+0.8004  IRMARIT_2.0\n",
      "+0.7836  IREDUHIGHST2_5.0\n",
      "+0.7585  CATAG6_4.0\n",
      "+0.7110  IRMARIT_3.0\n",
      "+0.7104  IREDUHIGHST2_3.0\n",
      "+0.6443  IRPYUD5MRJ_1.0\n",
      "+0.5384  IRINSUR4_1.0\n",
      "-0.5214  IREDUHIGHST2_11.0\n",
      "+0.5079  NEWRACE2_4.0\n",
      "-0.4675  NEWRACE2_5.0\n",
      "+0.4635  IRWRKSTAT18_4.0\n",
      "+0.4628  IREDUHIGHST2_6.0\n",
      "-0.4505  NEWRACE2_2.0\n",
      "-0.4436  INCOME_4.0\n",
      "-0.4376  IREDUHIGHST2_10.0\n",
      "+0.4268  CATAG6_5.0\n",
      "+0.4214  IRMARIT_4.0\n",
      "-0.4188  CATAG6_6.0\n",
      "+0.4052  IREDUHIGHST2_4.0\n",
      "+0.3884  IRWRKSTAT18_3.0\n",
      "+0.3658  CATAG6_3.0\n",
      "+0.3537  IRWRKSTAT18_2.0\n",
      "-0.3388  INCOME_3.0\n",
      "-0.2941  RSKCIGPKD_3.0\n",
      "-0.2930  NEWRACE2_6.0\n",
      "-0.2683  INCOME_2.0\n",
      "-0.2623  RSKMRJWK_4.0\n",
      "+0.2555  KSSLR6YR\n",
      "-0.2512  RSKCIGPKD_4.0\n",
      "-0.2327  NEWRACE2_7.0\n",
      "-0.2307  CATAG6_2.0\n",
      "+0.2094  IREDUHIGHST2_2.0\n",
      "-0.1840  IRALCFY\n",
      "-0.1748  IRMJFY\n",
      "+0.1660  IREDUHIGHST2_7.0\n",
      "+0.1620  NEWRACE2_3.0\n",
      "-0.1339  IREDUHIGHST2_9.0\n",
      "-0.0668  RSKMRJWK_2.0\n"
     ]
    }
   ],
   "source": [
    "target = \"SUTRTPY\"\n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "# Numeric (continuous count/score) features\n",
    "numeric_cols = [\"IRALCFY\", \"IRMJFY\", \"KSSLR6YR\"]\n",
    "\n",
    "# Treat coded fields as categorical (one-hot)\n",
    "categorical_cols = [\n",
    "    \"CATAG6\",\"IRSEX\",\"NEWRACE2\",\n",
    "    \"IRMARIT\",\"IREDUHIGHST2\",\"IRWRKSTAT18\",\n",
    "    \"IRINSUR4\",\"INCOME\",\n",
    "    \"IRPYUD5ALC\",\"IRPYUD5MRJ\",\"ILLYR\",\n",
    "    \"RSKCIGPKD\",\"RSKMRJWK\"\n",
    "]\n",
    "\n",
    "# Keep rows with target and weight\n",
    "work = df.loc[df[target].notna() & df[weight].notna()].copy()\n",
    "work[\"w_norm\"] = work[weight] / work[weight].mean()\n",
    "\n",
    "X = work[categorical_cols + numeric_cols]\n",
    "y = work[target].astype(int).to_numpy().ravel()\n",
    "w = work[\"w_norm\"].astype(float).to_numpy().ravel()\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.25, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocess (impute+encode categoricals, impute+scale numerics)\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, drop=\"first\"))\n",
    "        ]), categorical_cols),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler(with_mean=False))  # keep sparse compatibility\n",
    "        ]), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "# LASSO logistic (CV on C), weighted fit\n",
    "C_grid = np.logspace(-3, 1, 12)\n",
    "\n",
    "lasso_cv = LogisticRegressionCV(\n",
    "    Cs=C_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123),\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",\n",
    "    scoring=\"roc_auc\",\n",
    "    max_iter=10000,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", lasso_cv)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train, clf__sample_weight=w_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "auc    = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc    = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "print(f\"AUC (weighted): {auc:.3f}\")\n",
    "print(f\"Accuracy (weighted, thr=0.5): {acc:.3f}\")\n",
    "\n",
    "# Coefficients + selected features (non-zero)\n",
    "ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = list(ohe.get_feature_names_out(categorical_cols))\n",
    "feature_names = cat_names + numeric_cols\n",
    "\n",
    "coef = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "selected = [(name, float(wt)) for name, wt in zip(feature_names, coef) if wt != 0]\n",
    "\n",
    "print(f\"Selected features (non-zero): {len(selected)}\")\n",
    "for name, wt in sorted(selected, key=lambda x: abs(x[1]), reverse=True)[:40]:\n",
    "    print(f\"{wt:+.4f}  {name}\")\n",
    "\n",
    "# Metrics\n",
    "y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "auc    = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc    = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "with open(os.path.join(outdir + \"/SUTRTPY/lasso_output/\", f\"lasso_{target}_metrics.json\"), \"w\") as f:\n",
    "    json.dump({\"AUC_weighted\": float(auc),\n",
    "               \"Accuracy_weighted_thr0.5\": float(acc)}, f, indent=2)\n",
    "\n",
    "# Coefficients\n",
    "ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = list(ohe.get_feature_names_out(categorical_cols))\n",
    "feature_names = cat_names + numeric_cols\n",
    "\n",
    "coef = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coef})\n",
    "coef_df = coef_df.loc[coef_df[\"coef\"] != 0].copy()\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df.sort_values(\"abs_coef\", ascending=False, inplace=True)\n",
    "\n",
    "coef_df[[\"feature\",\"coef\"]].to_csv(\n",
    "    os.path.join(outdir + \"/SUTRTPY/lasso_output/\", f\"lasso_{target}_coefficients.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f4932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATAG6: reference = 1.0\n",
      "IRSEX: reference = 1.0\n",
      "NEWRACE2: reference = 1.0\n",
      "IRMARIT: reference = 1.0\n",
      "IREDUHIGHST2: reference = 1.0\n",
      "IRWRKSTAT18: reference = 1.0\n",
      "IRINSUR4: reference = 0.0\n",
      "INCOME: reference = 1.0\n",
      "IRPYUD5ALC: reference = 0.0\n",
      "IRPYUD5MRJ: reference = 0.0\n",
      "ILLYR: reference = 0.0\n",
      "RSKCIGPKD: reference = 1.0\n",
      "RSKMRJWK: reference = 1.0\n"
     ]
    }
   ],
   "source": [
    "ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "for var, cats, drop in zip(categorical_cols, ohe.categories_, ohe.drop_idx_):\n",
    "    if drop is not None:\n",
    "        ref = cats[drop]\n",
    "    else:\n",
    "        ref = \"None (no category dropped)\"\n",
    "    print(f\"{var}: reference = {ref}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017cf37",
   "metadata": {},
   "source": [
    "#### 4.2. Logistic Regression Model for SUTRTPY using variables captured by LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cecf9903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables included in final model:\n",
      "- IREDUHIGHST2\n",
      "- CATAG6\n",
      "- NEWRACE2\n",
      "- IRMARIT\n",
      "- IRWRKSTAT18\n",
      "- IRPYUD5ALC\n",
      "- ILLYR\n",
      "- INCOME\n",
      "- IRPYUD5MRJ\n",
      "- RSKCIGPKD\n",
      "\n",
      "Model fitting on 44,596 observations, 36 predictors.\n",
      "sum(freq_weights) = 44596.00000000001\n",
      "rank(X) vs cols: 36 36\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                SUTRTPY   No. Observations:                44596\n",
      "Model:                            GLM   Df Residuals:                 44560.00\n",
      "Model Family:                Binomial   Df Model:                           35\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -7027.8\n",
      "Date:                Sun, 09 Nov 2025   Deviance:                       14056.\n",
      "Time:                        21:29:16   Pearson chi2:                 4.45e+04\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):            0.04793\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -4.3860      0.349    -12.583      0.000      -5.069      -3.703\n",
      "IREDUHIGHST2_2      0.3331      0.490      0.680      0.497      -0.627       1.293\n",
      "IREDUHIGHST2_3      1.3006      0.516      2.519      0.012       0.289       2.312\n",
      "IREDUHIGHST2_4      0.9068      0.384      2.364      0.018       0.155       1.659\n",
      "IREDUHIGHST2_5      1.5404      0.346      4.456      0.000       0.863       2.218\n",
      "IREDUHIGHST2_6      0.8681      0.356      2.437      0.015       0.170       1.566\n",
      "IREDUHIGHST2_7      0.9305      0.334      2.790      0.005       0.277       1.584\n",
      "IREDUHIGHST2_8      0.6271      0.323      1.940      0.052      -0.006       1.261\n",
      "IREDUHIGHST2_9      0.5191      0.325      1.597      0.110      -0.118       1.156\n",
      "IREDUHIGHST2_10     0.2247      0.332      0.676      0.499      -0.426       0.876\n",
      "IREDUHIGHST2_11     0.1885      0.326      0.578      0.563      -0.451       0.828\n",
      "CATAG6_3            0.5272      0.089      5.925      0.000       0.353       0.702\n",
      "CATAG6_4            0.8650      0.088      9.845      0.000       0.693       1.037\n",
      "CATAG6_5            0.5355      0.096      5.604      0.000       0.348       0.723\n",
      "CATAG6_6           -0.3149      0.127     -2.477      0.013      -0.564      -0.066\n",
      "NEWRACE2_2         -0.6023      0.085     -7.119      0.000      -0.768      -0.436\n",
      "NEWRACE2_3          0.1560      0.265      0.589      0.556      -0.363       0.674\n",
      "NEWRACE2_4          0.2600      0.283      0.918      0.359      -0.295       0.815\n",
      "NEWRACE2_5         -0.5045      0.140     -3.599      0.000      -0.779      -0.230\n",
      "NEWRACE2_6         -0.2891      0.155     -1.864      0.062      -0.593       0.015\n",
      "NEWRACE2_7         -0.2545      0.067     -3.787      0.000      -0.386      -0.123\n",
      "IRMARIT_2.0         0.7502      0.118      6.363      0.000       0.519       0.981\n",
      "IRMARIT_3.0         0.6374      0.072      8.910      0.000       0.497       0.778\n",
      "IRMARIT_4.0         0.4542      0.072      6.294      0.000       0.313       0.596\n",
      "IRWRKSTAT18_2.0     0.3473      0.078      4.465      0.000       0.195       0.500\n",
      "IRWRKSTAT18_3.0     0.3472      0.100      3.481      0.001       0.152       0.543\n",
      "IRWRKSTAT18_4.0     0.4109      0.066      6.248      0.000       0.282       0.540\n",
      "IRPYUD5ALC_1        0.9048      0.058     15.528      0.000       0.791       1.019\n",
      "ILLYR_1.0           0.8983      0.058     15.370      0.000       0.784       1.013\n",
      "INCOME_2           -0.3968      0.067     -5.911      0.000      -0.528      -0.265\n",
      "INCOME_3           -0.4454      0.086     -5.207      0.000      -0.613      -0.278\n",
      "INCOME_4           -0.6427      0.078     -8.244      0.000      -0.795      -0.490\n",
      "IRPYUD5MRJ_1        0.5450      0.069      7.929      0.000       0.410       0.680\n",
      "RSKCIGPKD_2.0       0.0638      0.121      0.526      0.599      -0.174       0.302\n",
      "RSKCIGPKD_3.0      -0.2145      0.105     -2.043      0.041      -0.420      -0.009\n",
      "RSKCIGPKD_4.0      -0.2250      0.097     -2.311      0.021      -0.416      -0.034\n",
      "===================================================================================\n",
      "\n",
      "Top predictors by OR:\n",
      "                      OR      2.5%      97.5%       p-value\n",
      "IREDUHIGHST2_5  4.666290  2.369715   9.188555  8.367694e-06\n",
      "IREDUHIGHST2_3  3.671431  1.334782  10.098583  1.175783e-02\n",
      "IREDUHIGHST2_7  2.535792  1.318907   4.875432  5.272596e-03\n",
      "IREDUHIGHST2_4  2.476482  1.167525   5.252962  1.809474e-02\n",
      "IRPYUD5ALC_1    2.471516  2.204774   2.770529  2.231138e-54\n",
      "ILLYR_1.0       2.455324  2.189592   2.753306  2.595208e-53\n",
      "IREDUHIGHST2_6  2.382465  1.185062   4.789740  1.482974e-02\n",
      "CATAG6_4        2.375025  1.999300   2.821360  7.216985e-23\n",
      "IRMARIT_2.0     2.117360  1.680501   2.667785  1.980962e-10\n",
      "IRMARIT_3.0     1.891466  1.644044   2.176124  5.080678e-19\n",
      "IREDUHIGHST2_8  1.872087  0.993583   3.527347  5.237412e-02\n",
      "IRPYUD5MRJ_1    1.724637  1.507258   1.973367  2.211532e-15\n",
      "CATAG6_5        1.708325  1.416556   2.060189  2.091723e-08\n",
      "CATAG6_3        1.694200  1.423079   2.016973  3.115559e-09\n",
      "IREDUHIGHST2_9  1.680448  0.888839   3.177072  1.101916e-01\n",
      "\n",
      "Lowest predictors by OR:\n",
      "                       OR      2.5%     97.5%       p-value\n",
      "IREDUHIGHST2_10  1.252008  0.652829  2.401126  4.987525e-01\n",
      "IREDUHIGHST2_11  1.207476  0.636989  2.288890  5.634062e-01\n",
      "NEWRACE2_3       1.168773  0.695882  1.963022  5.555365e-01\n",
      "RSKCIGPKD_2.0    1.065917  0.840168  1.352325  5.990831e-01\n",
      "RSKCIGPKD_3.0    0.806963  0.656871  0.991351  4.108272e-02\n",
      "RSKCIGPKD_4.0    0.798527  0.659810  0.966408  2.083646e-02\n",
      "NEWRACE2_7       0.775322  0.679643  0.884469  1.525599e-04\n",
      "NEWRACE2_6       0.748928  0.552631  1.014951  6.228378e-02\n",
      "CATAG6_6         0.729839  0.568865  0.936363  1.324358e-02\n",
      "INCOME_2         0.672441  0.589529  0.767014  3.406270e-09\n",
      "INCOME_3         0.640573  0.541706  0.757484  1.915917e-07\n",
      "NEWRACE2_5       0.603785  0.458730  0.794708  3.193329e-04\n",
      "NEWRACE2_2       0.547575  0.463914  0.646323  1.083845e-12\n",
      "INCOME_4         0.525871  0.451359  0.612684  1.662019e-16\n",
      "const            0.012450  0.006287  0.024653  2.627458e-36\n"
     ]
    }
   ],
   "source": [
    "target = \"SUTRTPY\"\n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "# Top 10 LASSO predictors by absolute coefficient\n",
    "top_lasso_features = [\n",
    "    \"IREDUHIGHST2\", \"CATAG6\", \"NEWRACE2\", \"IRMARIT\", \"IRWRKSTAT18\",\n",
    "    \"IRPYUD5ALC\", \"ILLYR\", \"INCOME\", \"IRPYUD5MRJ\", \"RSKCIGPKD\"\n",
    "]\n",
    "\n",
    "selected_features = list(dict.fromkeys(top_lasso_features))  # ensure uniqueness\n",
    "\n",
    "print(\"Variables included in final model:\")\n",
    "for v in selected_features:\n",
    "    print(\"-\", v)\n",
    "\n",
    "# Prepare data\n",
    "cols_for_model = [target, weight] + selected_features\n",
    "work = df.loc[df[target].notna() & df[weight].notna(), cols_for_model].copy()\n",
    "work[target] = pd.to_numeric(work[target], errors=\"coerce\")\n",
    "work[weight] = pd.to_numeric(work[weight], errors=\"coerce\")\n",
    "work = work.dropna(subset=selected_features)\n",
    "# Identify numeric predictors (continuous)\n",
    "numeric_cols = [\"KSSLR6YR\"]\n",
    "categorical_cols = [c for c in selected_features if c not in numeric_cols]\n",
    "\n",
    "# Median impute numeric\n",
    "#for c in numeric_cols:\n",
    "#    med = pd.to_numeric(work[c], errors=\"coerce\").median()\n",
    "#    work[c] = pd.to_numeric(work[c], errors=\"coerce\").fillna(med)\n",
    "\n",
    "# Dummy encoding and cleanup\n",
    "X_parts = []\n",
    "for c in categorical_cols:\n",
    "    # replace NaN with a literal \"Missing\" category\n",
    "    work[c] = work[c].astype(\"category\")\n",
    "    dummies = pd.get_dummies(work[c], prefix=c, drop_first=True)\n",
    "    X_parts.append(dummies)\n",
    "\n",
    "X_cat = pd.concat(X_parts, axis=1)\n",
    "#X_num = work[numeric_cols]\n",
    "X = pd.concat([X_cat], axis=1)\n",
    "\n",
    "# Coerce to numeric and clean\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "y = pd.to_numeric(work[target], errors=\"coerce\")\n",
    "w = pd.to_numeric(work[weight], errors=\"coerce\")\n",
    "\n",
    "keep = X.notna().all(axis=1) & y.notna() & w.notna()\n",
    "X = X.loc[keep]\n",
    "y = y.loc[keep]\n",
    "w = w.loc[keep]\n",
    "\n",
    "# Drop constant or duplicate columns\n",
    "X = X.loc[:, X.nunique(dropna=False) > 1]\n",
    "X = X.loc[:, ~X.T.duplicated()]\n",
    "\n",
    "# Add intercept\n",
    "X = sm.add_constant(X).astype(float)\n",
    "y = y.astype(float)\n",
    "w = w.astype(float)\n",
    "\n",
    "print(f\"\\nModel fitting on {len(X):,} observations, {X.shape[1]} predictors.\")\n",
    "\n",
    "# weighted logistic regression (robust SEs)\n",
    "N = len(w)\n",
    "w_freq = w * (N / w.sum())   # scale such that sum(w_freq) == N\n",
    "\n",
    "print(\"sum(freq_weights) =\", w_freq.sum())  # sanity: should equal N\n",
    "print(\"rank(X) vs cols:\", np.linalg.matrix_rank(X.values), X.shape[1])\n",
    "\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=w_freq).fit(cov_type=\"HC1\")\n",
    "print(model.summary())\n",
    "\n",
    "# Compute Odds Ratios with 95% CI\n",
    "ci = model.conf_int()\n",
    "ci.columns = [\"2.5%\", \"97.5%\"]\n",
    "or_table = pd.DataFrame({\n",
    "    \"OR\": np.exp(model.params),\n",
    "    \"2.5%\": np.exp(ci[\"2.5%\"]),\n",
    "    \"97.5%\": np.exp(ci[\"97.5%\"]),\n",
    "    \"p-value\": model.pvalues\n",
    "}).sort_values(\"OR\", ascending=False)\n",
    "\n",
    "print(\"\\nTop predictors by OR:\")\n",
    "print(or_table.head(15))\n",
    "\n",
    "print(\"\\nLowest predictors by OR:\")\n",
    "print(or_table.tail(15))\n",
    "\n",
    "# Save text summary\n",
    "with open(os.path.join(outdir + \"/SUTRTPY/glm_output/\", f\"glm_{target}_summary.txt\"), \"w\") as f:\n",
    "    f.write(model.summary().as_text())\n",
    "\n",
    "# Save full OR table\n",
    "or_table.to_csv(os.path.join(outdir + \"/SUTRTPY/glm_output/\", f\"glm_{target}_or_table.csv\"))\n",
    "\n",
    "# Save compact (manuscript-ready) table\n",
    "nice = or_table.copy()\n",
    "nice[\"OR (95% CI)\"] = nice.apply(lambda r: f'{r[\"OR\"]:.2f} ({r[\"2.5%\"]:.2f}, {r[\"97.5%\"]:.2f})', axis=1)\n",
    "nice = nice[[\"OR (95% CI)\", \"p-value\"]]\n",
    "nice.to_csv(os.path.join(outdir + \"/SUTRTPY/glm_output/\", f\"glm_{target}_or_table_compact.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe174ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference levels (inferred from dummy columns):\n",
      "- IREDUHIGHST2: 1\n",
      "- CATAG6: 2\n",
      "- NEWRACE2: 1\n",
      "- IRMARIT: 1.0\n",
      "- IRWRKSTAT18: 1.0\n",
      "- IRPYUD5ALC: 0\n",
      "- ILLYR: 0.0\n",
      "- INCOME: 1\n",
      "- IRPYUD5MRJ: 0\n",
      "- RSKCIGPKD: 1.0\n"
     ]
    }
   ],
   "source": [
    "ref_inferred = {}\n",
    "for c in categorical_cols:\n",
    "    cats = list(work[c].cat.categories)\n",
    "    kept = [col.split(f\"{c}_\", 1)[1] for col in X_cat.columns if col.startswith(f\"{c}_\")]\n",
    "    # the missing one is the dropped reference\n",
    "    ref = [cat for cat in cats if str(cat) not in kept][0]\n",
    "    ref_inferred[c] = ref\n",
    "print(\"Reference levels (inferred from dummy columns):\")\n",
    "for k, v in ref_inferred.items():\n",
    "    print(f\"- {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a65125",
   "metadata": {},
   "source": [
    "#### 4.3. Random Forest Model for SUTRTPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f18aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest results for SUTRTPY:\n",
      "AUC (weighted): 0.782\n",
      "Accuracy (weighted, thr=0.5): 0.957\n"
     ]
    }
   ],
   "source": [
    "target = \"SUTRTPY\"   \n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "numeric_cols = [\"IRALCFY\", \"IRMJFY\", \"KSSLR6YR\"]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"CATAG6\",\"IRSEX\",\"NEWRACE2\",\n",
    "    \"IRMARIT\",\"IREDUHIGHST2\",\"IRWRKSTAT18\",\n",
    "    \"IRINSUR4\",\"INCOME\",\n",
    "    \"IRPYUD5ALC\",\"IRPYUD5MRJ\",\"ILLYR\",\n",
    "    \"RSKCIGPKD\",\"RSKMRJWK\"\n",
    "]\n",
    "\n",
    "work = df.loc[df[target].notna() & df[weight].notna()].copy()\n",
    "work[\"w_norm\"] = work[weight] / work[weight].mean()\n",
    "\n",
    "X = work[categorical_cols + numeric_cols]\n",
    "y = work[target].astype(int).to_numpy().ravel()\n",
    "w = work[\"w_norm\"].astype(float).to_numpy().ravel()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.25, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\"))\n",
    "        ]), categorical_cols),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=123,\n",
    "    n_jobs=-1,\n",
    "    class_weight=None  \n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", rf)\n",
    "])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train, clf__sample_weight=w_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob = pipe_rf.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "print(f\"\\nRandom Forest results for {target}:\")\n",
    "print(f\"AUC (weighted): {auc:.3f}\")\n",
    "print(f\"Accuracy (weighted, thr=0.5): {acc:.3f}\")\n",
    "\n",
    "metrics = {\n",
    "    \"target\": target,\n",
    "    \"AUC_weighted\": float(auc),\n",
    "    \"Accuracy_weighted_thr0.5\": float(acc),\n",
    "    \"N_train\": len(y_train),\n",
    "    \"N_test\": len(y_test)\n",
    "}\n",
    "\n",
    "# Save metrics JSON\n",
    "with open(os.path.join(outdir + \"/SUTRTPY/rf_output/\", f\"rf_{target}_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Feature Importance\n",
    "# Get feature names after preprocessing\n",
    "cat_names = pipe_rf.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_names) + numeric_cols\n",
    "\n",
    "importances = pipe_rf.named_steps[\"clf\"].feature_importances_\n",
    "imp_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "imp_df = imp_df.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "imp_df.to_csv(os.path.join(outdir + \"/SUTRTPY/rf_output/\", f\"rf_{target}_feature_importance.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcceaa6",
   "metadata": {},
   "source": [
    "#### 4.4. LASSO Logistic Regression Model for MHTRTPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dff1d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (weighted): 0.701\n",
      "Accuracy (weighted, thr=0.5): 0.775\n",
      "Selected features (non-zero): 44\n",
      "-1.2454  CATAG6_6.0\n",
      "-0.8819  CATAG6_5.0\n",
      "-0.8357  NEWRACE2_2.0\n",
      "-0.8165  CATAG6_2.0\n",
      "-0.8074  NEWRACE2_5.0\n",
      "+0.7342  IRSEX_2.0\n",
      "-0.6494  NEWRACE2_4.0\n",
      "-0.6404  CATAG6_3.0\n",
      "-0.6379  CATAG6_4.0\n",
      "+0.5687  IRINSUR4_1.0\n",
      "+0.5682  ILLYR_1.0\n",
      "-0.5633  RSKMRJWK_4.0\n",
      "-0.5455  NEWRACE2_7.0\n",
      "+0.4205  IRPYUD5ALC_1.0\n",
      "+0.4168  RSKCIGPKD_4.0\n",
      "+0.4141  RSKCIGPKD_3.0\n",
      "+0.3628  IREDUHIGHST2_11.0\n",
      "+0.3333  IRMARIT_3.0\n",
      "-0.3323  IREDUHIGHST2_7.0\n",
      "+0.3163  IRPYUD5MRJ_1.0\n",
      "-0.2861  NEWRACE2_3.0\n",
      "+0.2708  IRWRKSTAT18_4.0\n",
      "+0.2621  IRWRKSTAT18_2.0\n",
      "-0.2540  IREDUHIGHST2_8.0\n",
      "+0.2385  RSKCIGPKD_2.0\n",
      "+0.2012  KSSLR6YR\n",
      "+0.1776  IRMARIT_4.0\n",
      "-0.1683  RSKMRJWK_3.0\n",
      "+0.1338  IREDUHIGHST2_9.0\n",
      "+0.1329  IRWRKSTAT18_3.0\n",
      "-0.1235  IRALCFY\n",
      "-0.1149  IREDUHIGHST2_6.0\n",
      "-0.1042  IREDUHIGHST2_4.0\n",
      "+0.0814  IREDUHIGHST2_2.0\n",
      "+0.0732  IREDUHIGHST2_10.0\n",
      "+0.0683  INCOME_3.0\n",
      "-0.0676  INCOME_4.0\n",
      "-0.0658  NEWRACE2_6.0\n",
      "+0.0402  RSKMRJWK_2.0\n",
      "-0.0371  IREDUHIGHST2_3.0\n"
     ]
    }
   ],
   "source": [
    "target = \"MHTRTPY\"\n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "# Numeric (continuous count/score) features\n",
    "numeric_cols = [\"IRALCFY\", \"IRMJFY\", \"KSSLR6YR\"]\n",
    "\n",
    "# Treat coded fields as categorical (one-hot)\n",
    "categorical_cols = [\n",
    "    \"CATAG6\",\"IRSEX\",\"NEWRACE2\",\n",
    "    \"IRMARIT\",\"IREDUHIGHST2\",\"IRWRKSTAT18\",\n",
    "    \"IRINSUR4\",\"INCOME\",\n",
    "    \"IRPYUD5ALC\",\"IRPYUD5MRJ\",\"ILLYR\",\n",
    "    \"RSKCIGPKD\",\"RSKMRJWK\"\n",
    "]\n",
    "\n",
    "# Keep rows with target and weight\n",
    "work = df.loc[df[target].notna() & df[weight].notna()].copy()\n",
    "work[\"w_norm\"] = work[weight] / work[weight].mean()\n",
    "\n",
    "X = work[categorical_cols + numeric_cols]\n",
    "y = work[target].astype(int).to_numpy().ravel()\n",
    "w = work[\"w_norm\"].astype(float).to_numpy().ravel()\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.25, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocess (impute+encode categoricals, impute+scale numerics)\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, drop=\"first\"))\n",
    "        ]), categorical_cols),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler(with_mean=False))  # keep sparse compatibility\n",
    "        ]), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "# LASSO logistic (CV on C), weighted fit\n",
    "C_grid = np.logspace(-3, 1, 12)\n",
    "\n",
    "lasso_cv = LogisticRegressionCV(\n",
    "    Cs=C_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123),\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",\n",
    "    scoring=\"roc_auc\",\n",
    "    max_iter=10000,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", lasso_cv)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train, clf__sample_weight=w_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "auc    = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc    = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "print(f\"AUC (weighted): {auc:.3f}\")\n",
    "print(f\"Accuracy (weighted, thr=0.5): {acc:.3f}\")\n",
    "\n",
    "# Coefficients + selected features (non-zero)\n",
    "ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = list(ohe.get_feature_names_out(categorical_cols))\n",
    "feature_names = cat_names + numeric_cols\n",
    "\n",
    "coef = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "selected = [(name, float(wt)) for name, wt in zip(feature_names, coef) if wt != 0]\n",
    "\n",
    "print(f\"Selected features (non-zero): {len(selected)}\")\n",
    "for name, wt in sorted(selected, key=lambda x: abs(x[1]), reverse=True)[:40]:\n",
    "    print(f\"{wt:+.4f}  {name}\")\n",
    "\n",
    "# Metrics\n",
    "y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "auc    = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc    = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "with open(os.path.join(outdir + \"/MHTRTPY/lasso_output/\", f\"lasso_{target}_metrics.json\"), \"w\") as f:\n",
    "    json.dump({\"AUC_weighted\": float(auc),\n",
    "               \"Accuracy_weighted_thr0.5\": float(acc)}, f, indent=2)\n",
    "\n",
    "# Coefficients \n",
    "ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_names = list(ohe.get_feature_names_out(categorical_cols))\n",
    "feature_names = cat_names + numeric_cols\n",
    "\n",
    "coef = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coef})\n",
    "coef_df = coef_df.loc[coef_df[\"coef\"] != 0].copy()\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df.sort_values(\"abs_coef\", ascending=False, inplace=True)\n",
    "\n",
    "coef_df[[\"feature\",\"coef\"]].to_csv(\n",
    "    os.path.join(outdir + \"/MHTRTPY/lasso_output/\", f\"lasso_{target}_coefficients.csv\"), index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7a502",
   "metadata": {},
   "source": [
    "#### 4.5. Logistic Regression Model for MHTRTPY using variables captured by LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ccd532fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables included in MHTRTPY model:\n",
      "- CATAG6\n",
      "- NEWRACE2\n",
      "- IREDUHIGHST2\n",
      "- RSKCIGPKD\n",
      "- RSKMRJWK\n",
      "- IRSEX\n",
      "- IRWRKSTAT18\n",
      "- IRINSUR4\n",
      "- ILLYR\n",
      "- IRMARIT\n",
      "\n",
      "Model fitting on 44,365 observations, 36 predictors.\n",
      "sum(freq_weights) = 44365.0\n",
      "rank(X) vs cols: 36 36\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                MHTRTPY   No. Observations:                44365\n",
      "Model:                            GLM   Df Residuals:                    44329\n",
      "Model Family:                Binomial   Df Model:                           35\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -21829.\n",
      "Date:                Sun, 09 Nov 2025   Deviance:                       43658.\n",
      "Time:                        22:41:22   Pearson chi2:                 4.50e+04\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.09566\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -2.6495      0.180    -14.742      0.000      -3.002      -2.297\n",
      "CATAG6_3            0.1006      0.045      2.259      0.024       0.013       0.188\n",
      "CATAG6_4            0.0592      0.045      1.327      0.184      -0.028       0.147\n",
      "CATAG6_5           -0.1834      0.048     -3.827      0.000      -0.277      -0.089\n",
      "CATAG6_6           -0.6832      0.055    -12.414      0.000      -0.791      -0.575\n",
      "NEWRACE2_2         -0.8508      0.044    -19.493      0.000      -0.936      -0.765\n",
      "NEWRACE2_3         -0.1691      0.177     -0.955      0.339      -0.516       0.178\n",
      "NEWRACE2_4         -0.8689      0.233     -3.729      0.000      -1.325      -0.412\n",
      "NEWRACE2_5         -0.8177      0.061    -13.405      0.000      -0.937      -0.698\n",
      "NEWRACE2_6         -0.0187      0.079     -0.237      0.812      -0.173       0.136\n",
      "NEWRACE2_7         -0.5356      0.036    -14.850      0.000      -0.606      -0.465\n",
      "IREDUHIGHST2_2      0.3286      0.233      1.411      0.158      -0.128       0.785\n",
      "IREDUHIGHST2_3      0.2431      0.350      0.694      0.488      -0.444       0.930\n",
      "IREDUHIGHST2_4     -0.3424      0.229     -1.493      0.135      -0.792       0.107\n",
      "IREDUHIGHST2_5      0.3441      0.187      1.838      0.066      -0.023       0.711\n",
      "IREDUHIGHST2_6      0.1475      0.185      0.796      0.426      -0.216       0.511\n",
      "IREDUHIGHST2_7     -0.2312      0.170     -1.362      0.173      -0.564       0.102\n",
      "IREDUHIGHST2_8     -0.1076      0.158     -0.683      0.494      -0.416       0.201\n",
      "IREDUHIGHST2_9      0.1860      0.158      1.178      0.239      -0.123       0.495\n",
      "IREDUHIGHST2_10     0.2024      0.160      1.265      0.206      -0.111       0.516\n",
      "IREDUHIGHST2_11     0.4112      0.157      2.613      0.009       0.103       0.720\n",
      "RSKCIGPKD_2.0       0.1414      0.078      1.815      0.070      -0.011       0.294\n",
      "RSKCIGPKD_3.0       0.3272      0.066      4.940      0.000       0.197       0.457\n",
      "RSKCIGPKD_4.0       0.3595      0.063      5.666      0.000       0.235       0.484\n",
      "RSKMRJWK_2.0        0.0788      0.033      2.378      0.017       0.014       0.144\n",
      "RSKMRJWK_3.0       -0.2099      0.039     -5.409      0.000      -0.286      -0.134\n",
      "RSKMRJWK_4.0       -0.5436      0.043    -12.585      0.000      -0.628      -0.459\n",
      "IRSEX_2             0.7089      0.025     28.144      0.000       0.660       0.758\n",
      "IRWRKSTAT18_2.0     0.3214      0.037      8.660      0.000       0.249       0.394\n",
      "IRWRKSTAT18_3.0     0.1371      0.062      2.203      0.028       0.015       0.259\n",
      "IRWRKSTAT18_4.0     0.3595      0.032     11.345      0.000       0.297       0.422\n",
      "IRINSUR4_1.0        0.5685      0.050     11.421      0.000       0.471       0.666\n",
      "ILLYR_1.0           0.6199      0.028     21.864      0.000       0.564       0.675\n",
      "IRMARIT_2.0         0.1563      0.058      2.679      0.007       0.042       0.271\n",
      "IRMARIT_3.0         0.4604      0.035     13.053      0.000       0.391       0.530\n",
      "IRMARIT_4.0         0.2683      0.034      7.939      0.000       0.202       0.335\n",
      "===================================================================================\n",
      "\n",
      "Top predictors by OR:\n",
      "                       OR      2.5%     97.5%        p-value\n",
      "IRSEX_2          2.031734  1.933868  2.134552  2.827726e-174\n",
      "ILLYR_1.0        1.858781  1.758301  1.965003  5.773659e-106\n",
      "IRINSUR4_1.0     1.765566  1.601462  1.946486   3.278807e-30\n",
      "IRMARIT_3.0      1.584780  1.478915  1.698224   6.101783e-39\n",
      "IREDUHIGHST2_11  1.508702  1.108296  2.053768   8.965214e-03\n",
      "RSKCIGPKD_4.0    1.432625  1.265096  1.622340   1.462066e-08\n",
      "IRWRKSTAT18_4.0  1.432608  1.346338  1.524405   7.872870e-30\n",
      "IREDUHIGHST2_5   1.410731  0.977344  2.036296   6.612323e-02\n",
      "IREDUHIGHST2_2   1.388959  0.880133  2.191949   1.581119e-01\n",
      "RSKCIGPKD_3.0    1.387137  1.218243  1.579446   7.809032e-07\n",
      "IRWRKSTAT18_2.0  1.379049  1.282297  1.483101   4.726934e-18\n",
      "IRMARIT_4.0      1.307702  1.223899  1.397242   2.036202e-15\n",
      "IREDUHIGHST2_3   1.275174  0.641642  2.534228   4.878751e-01\n",
      "IREDUHIGHST2_10  1.224328  0.894785  1.675238   2.058449e-01\n",
      "IREDUHIGHST2_9   1.204451  0.883891  1.641269   2.387017e-01\n",
      "\n",
      "Lowest predictors by OR:\n",
      "                      OR      2.5%     97.5%       p-value\n",
      "CATAG6_4        1.061020  0.972165  1.157995  1.843951e-01\n",
      "NEWRACE2_6      0.981468  0.840986  1.145416  8.123908e-01\n",
      "IREDUHIGHST2_8  0.897957  0.659433  1.222759  4.944330e-01\n",
      "NEWRACE2_3      0.844418  0.596861  1.194652  3.394381e-01\n",
      "CATAG6_5        0.832476  0.757870  0.914426  1.295135e-04\n",
      "RSKMRJWK_3.0    0.810683  0.751313  0.874746  6.352664e-08\n",
      "IREDUHIGHST2_7  0.793560  0.568926  1.106888  1.732453e-01\n",
      "IREDUHIGHST2_4  0.710052  0.452987  1.112999  1.354030e-01\n",
      "NEWRACE2_7      0.585323  0.545374  0.628198  7.002998e-50\n",
      "RSKMRJWK_4.0    0.580683  0.533549  0.631981  2.568504e-36\n",
      "CATAG6_6        0.505008  0.453371  0.562526  2.195830e-35\n",
      "NEWRACE2_5      0.441449  0.391704  0.497511  5.652675e-41\n",
      "NEWRACE2_2      0.427066  0.392050  0.465209  1.262503e-84\n",
      "NEWRACE2_4      0.419427  0.265671  0.662171  1.919789e-04\n",
      "const           0.070690  0.049702  0.100540  3.481898e-49\n"
     ]
    }
   ],
   "source": [
    "target = \"MHTRTPY\"\n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "# Top 10 LASSO predictors\n",
    "top_lasso_features = [\n",
    "    \"CATAG6\", \"NEWRACE2\", \"IREDUHIGHST2\", \"RSKCIGPKD\", \"RSKMRJWK\",\n",
    "    \"IRSEX\", \"IRWRKSTAT18\", \"IRINSUR4\", \"ILLYR\", \"IRMARIT\"\n",
    "]\n",
    "\n",
    "selected_features = list(dict.fromkeys(top_lasso_features))\n",
    "\n",
    "print(\"Variables included in MHTRTPY model:\")\n",
    "for v in selected_features:\n",
    "    print(\"-\", v)\n",
    "\n",
    "# Prepare data\n",
    "cols_for_model = [target, weight] + selected_features\n",
    "work = df.loc[df[target].notna() & df[weight].notna(), cols_for_model].copy()\n",
    "work[target] = pd.to_numeric(work[target], errors=\"coerce\")\n",
    "work[weight] = pd.to_numeric(work[weight], errors=\"coerce\")\n",
    "work = work.dropna(subset=selected_features)\n",
    "\n",
    "# Numeric vs categorical\n",
    "numeric_cols = [\"KSSLR6YR\"]\n",
    "categorical_cols = [c for c in selected_features if c not in numeric_cols]\n",
    "\n",
    "# Median impute numeric\n",
    "#for c in numeric_cols:\n",
    "#    med = pd.to_numeric(work[c], errors=\"coerce\").median()\n",
    "#    work[c] = pd.to_numeric(work[c], errors=\"coerce\").fillna(med)\n",
    "\n",
    "# Dummy encoding (explicit Missing category)\n",
    "X_parts = []\n",
    "for c in categorical_cols:\n",
    "    work[c] = work[c].astype(\"category\")\n",
    "    dummies = pd.get_dummies(work[c], prefix=c, drop_first=True)\n",
    "    X_parts.append(dummies)\n",
    "\n",
    "X_cat = pd.concat(X_parts, axis=1)\n",
    "#X_num = work[numeric_cols]\n",
    "X = pd.concat([X_cat], axis=1)\n",
    "\n",
    "# Clean dtypes\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "y = pd.to_numeric(work[target], errors=\"coerce\")\n",
    "w = pd.to_numeric(work[weight], errors=\"coerce\")\n",
    "\n",
    "keep = X.notna().all(axis=1) & y.notna() & w.notna()\n",
    "X = X.loc[keep]\n",
    "y = y.loc[keep]\n",
    "w = w.loc[keep]\n",
    "\n",
    "# Drop constants/duplicates\n",
    "X = X.loc[:, X.nunique(dropna=False) > 1]\n",
    "X = X.loc[:, ~X.T.duplicated()]\n",
    "\n",
    "# Add constant\n",
    "X = sm.add_constant(X).astype(float)\n",
    "y = y.astype(float)\n",
    "w = w.astype(float)\n",
    "\n",
    "# Fit weighted logistic regression (robust SEs)\n",
    "N = len(w)\n",
    "w_freq = w * (N / w.sum())   # scaled so sum(weights) == N\n",
    "\n",
    "print(f\"\\nModel fitting on {N:,} observations, {X.shape[1]} predictors.\")\n",
    "print(\"sum(freq_weights) =\", w_freq.sum())\n",
    "print(\"rank(X) vs cols:\", np.linalg.matrix_rank(X.values), X.shape[1])\n",
    "\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=w_freq).fit(cov_type=\"HC1\")\n",
    "print(model.summary())\n",
    "\n",
    "# Compute Odds Ratios with 95% CI\n",
    "ci = model.conf_int()\n",
    "ci.columns = [\"2.5%\", \"97.5%\"]\n",
    "or_table = pd.DataFrame({\n",
    "    \"OR\": np.exp(model.params),\n",
    "    \"2.5%\": np.exp(ci[\"2.5%\"]),\n",
    "    \"97.5%\": np.exp(ci[\"97.5%\"]),\n",
    "    \"p-value\": model.pvalues\n",
    "}).sort_values(\"OR\", ascending=False)\n",
    "\n",
    "print(\"\\nTop predictors by OR:\")\n",
    "print(or_table.head(15))\n",
    "print(\"\\nLowest predictors by OR:\")\n",
    "print(or_table.tail(15))\n",
    "\n",
    "# Save text summary \n",
    "with open(os.path.join(outdir + \"/MHTRTPY/glm_output/\", f\"glm_{target}_summary.txt\"), \"w\") as f:\n",
    "    f.write(model.summary().as_text())\n",
    "\n",
    "# Save full OR table\n",
    "or_table.to_csv(os.path.join(outdir + \"/MHTRTPY/glm_output/\", f\"glm_{target}_or_table.csv\"))\n",
    "\n",
    "# Save compact (manuscript-ready) table\n",
    "nice = or_table.copy()\n",
    "nice[\"OR (95% CI)\"] = nice.apply(lambda r: f'{r[\"OR\"]:.2f} ({r[\"2.5%\"]:.2f}, {r[\"97.5%\"]:.2f})', axis=1)\n",
    "nice = nice[[\"OR (95% CI)\", \"p-value\"]]\n",
    "nice.to_csv(os.path.join(outdir + \"/MHTRTPY/glm_output/\", f\"glm_{target}_or_table_compact.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3501e",
   "metadata": {},
   "source": [
    "#### 4.6. Random Forest Model for MHTRTPY   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf50a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest results for MHTRTPY:\n",
      "AUC (weighted): 0.726\n",
      "Accuracy (weighted, thr=0.5): 0.785\n"
     ]
    }
   ],
   "source": [
    "target = \"MHTRTPY\"   \n",
    "weight = \"ANALWT2_C\"\n",
    "\n",
    "numeric_cols = [\"IRALCFY\", \"IRMJFY\", \"KSSLR6YR\"]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"CATAG6\",\"IRSEX\",\"NEWRACE2\",\n",
    "    \"IRMARIT\",\"IREDUHIGHST2\",\"IRWRKSTAT18\",\n",
    "    \"IRINSUR4\",\"INCOME\",\n",
    "    \"IRPYUD5ALC\",\"IRPYUD5MRJ\",\"ILLYR\", \n",
    "    \"RSKCIGPKD\",\"RSKMRJWK\"\n",
    "]\n",
    "\n",
    "work = df.loc[df[target].notna() & df[weight].notna()].copy()\n",
    "work[\"w_norm\"] = work[weight] / work[weight].mean()\n",
    "\n",
    "X = work[categorical_cols + numeric_cols]\n",
    "y = work[target].astype(int).to_numpy().ravel()\n",
    "w = work[\"w_norm\"].astype(float).to_numpy().ravel()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.25, random_state=123, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\"))\n",
    "        ]), categorical_cols),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=123,\n",
    "    n_jobs=-1,\n",
    "    class_weight=None  \n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", rf)\n",
    "])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train, clf__sample_weight=w_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob = pipe_rf.predict_proba(X_test)[:, 1]\n",
    "y_hat  = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob, sample_weight=w_test)\n",
    "acc = accuracy_score(y_test, y_hat, sample_weight=w_test)\n",
    "\n",
    "print(f\"\\nRandom Forest results for {target}:\")\n",
    "print(f\"AUC (weighted): {auc:.3f}\")\n",
    "print(f\"Accuracy (weighted, thr=0.5): {acc:.3f}\")\n",
    "\n",
    "metrics = {\n",
    "    \"target\": target,\n",
    "    \"AUC_weighted\": float(auc),\n",
    "    \"Accuracy_weighted_thr0.5\": float(acc),\n",
    "    \"N_train\": len(y_train),\n",
    "    \"N_test\": len(y_test)\n",
    "}\n",
    "\n",
    "# Save metrics JSON\n",
    "with open(os.path.join(outdir + \"/MHTRTPY/rf_output/\", f\"rf_{target}_metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Feature Importance\n",
    "# Get feature names after preprocessing\n",
    "cat_names = pipe_rf.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"ohe\"].get_feature_names_out(categorical_cols)\n",
    "feature_names = list(cat_names) + numeric_cols\n",
    "\n",
    "importances = pipe_rf.named_steps[\"clf\"].feature_importances_\n",
    "imp_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "imp_df = imp_df.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "imp_df.to_csv(os.path.join(outdir + \"/MHTRTPY/rf_output/\", f\"rf_{target}_feature_importance.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
